{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # np.array operations\n",
    "import pandas as pd # pd.DataFrame operations, save / read csv\n",
    "from skimage.io import imread # read images\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plot images\n",
    "\n",
    "from scipy.signal import convolve2d # filter images\n",
    "from scipy.ndimage.interpolation import rotate # rotate images\n",
    "\n",
    "# haralick features\n",
    "from skimage import feature\n",
    "from skimage.feature import greycomatrix\n",
    "from skimage.feature import greycoprops\n",
    "from scipy.stats import entropy\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# utility functions\n",
    "# from sklearn.preprocessing import minmax_scale as mms\n",
    "from skimage.util.shape import view_as_blocks\n",
    "import scipy.stats as stats\n",
    "\n",
    "# multiprocessing\n",
    "from multiprocessing import Pool, Process, Array\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = pd.read_csv('../IC2017_DATA/valid_images.csv')\n",
    "n_images = len(paths)\n",
    "\n",
    "names_VI = [\"ExG\", \"ExGR\", \"CIVE\", \"VEG\", \"WI\", \"NGRDI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIC(image, levels):\n",
    "    \"\"\"\n",
    "    If blocks were 18 x 18 it would be easier to use the function in only the 16 x 16 core.\n",
    "    \"\"\"\n",
    "    _all = np.zeros(levels * 2, dtype = int)\n",
    "    border = _all[:levels]\n",
    "    interior = _all[levels:]\n",
    "    ns = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "    \n",
    "    lim_lin, lim_col = image.shape\n",
    "    test = {-1, 16}\n",
    "\n",
    "    for lin in range(lim_lin):\n",
    "        for col in range(lim_col): # laço do elementos da matriz\n",
    "            curr = image[lin, col]\n",
    "            interior[curr] += 1\n",
    "            for v, h in ns: # laço dos vizinhos\n",
    "                nl = lin + v\n",
    "                nc = col + h\n",
    "                if nl not in test and nc not in test: # teste de estar dentro da matriz\n",
    "                    if image[nl, nc] != curr:\n",
    "                        border[curr] += 1\n",
    "                        interior[curr] -=1\n",
    "                        break\n",
    "\n",
    "    return _all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Haralick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_func(P):\n",
    "    return [entropy(P[:, :, 0, i].ravel()) for i in range(P.shape[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxProb(P):\n",
    "    return [np.max(P[:, :, 0, i]) for i in range(P.shape[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(P):\n",
    "    \"\"\"\n",
    "    Cada medida retorna 4 valores (1 para cada angulo).\n",
    "    O valor 0 se refere ao fato de escolher sempre a mesma distância.\n",
    "    \"\"\"\n",
    "    contrast = greycoprops(P, prop = \"contrast\")[0 , :]\n",
    "    correlation = greycoprops(P, prop = \"correlation\")[0 , :]\n",
    "    energy = greycoprops(P, prop = \"ASM\")[0 , :]\n",
    "    homogeneity = greycoprops(P, prop = \"homogeneity\")[0 , :]\n",
    "    _maxProb = maxProb(P)\n",
    "    _entropy = entropy_func(P)\n",
    "    \n",
    "    #print(contrast, correlation, energy, homogeneity, _maxProb, _entropy)\n",
    "\n",
    "    return [*contrast, *correlation, *energy, *homogeneity, *_maxProb, *_entropy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4) Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(b):\n",
    "    return [np.min(b),\n",
    "            np.percentile(b, .25), np.percentile(b, .5), np.percentile(b, .75),\n",
    "            np.max(b), np.mean(b), np.std(b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features names\n",
    "\n",
    "extractors = [\"contrast\", \"correlation\", \"energy\", \"homogeneity\", \"maxprob\", \"entropy\"]\n",
    "angles = [\"np.pi/4\", \"0\", \"3*np.pi/2\", \"7*np.pi/4\"]\n",
    "statistics = [\"min\", \"q25\", \"q50\", \"q75\", \"max\", \"mean\", \"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotations = [\n",
    "#     (0, 0),\n",
    "#     (1, 15),\n",
    "#     (2, 30),\n",
    "#     (3, 45),\n",
    "# ]\n",
    "\n",
    "# shifts = [\n",
    "#     (0, 0, 0),\n",
    "#     (1, 0, 1),\n",
    "#     (2, 1, 0),\n",
    "#     (3, 1, 1),\n",
    "# ]\n",
    "\n",
    "# noises = [\n",
    "#     (0, 'None'),\n",
    "#     (1, 'Blur')\n",
    "# ]\n",
    "\n",
    "# n = 9\n",
    "# kernel_blur = np.zeros((n, n), int)\n",
    "# kernel_blur[n // 2, :] = 1\n",
    "# kernel_blur = kernel_blur / kernel_blur.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_img(img, noise, rotation, shift):\n",
    "    \n",
    "#     noise_num, noise_val = noise\n",
    "#     rot_num, rot_val = rotation\n",
    "#     sh_num, sh_val_v, sh_val_h = shift\n",
    "    \n",
    "#     if len(img.shape) == 3:\n",
    "#         if noise_val == 'Blur':\n",
    "#             for c in range(3):\n",
    "#                 img[:,:,c] = convolve2d(img[:,:,c], kernel_blur, mode = 'same', boundary = 'symm')\n",
    "\n",
    "#         if rot_num != 0:\n",
    "#             img = np.pad(img, ((256, 256), (256, 256), (0, 0)), mode = 'reflect')\n",
    "#             img = rotate(img, rot_val, reshape = False)\n",
    "#             img = img[150 + 2 : 150 + 724 - 2, 150 + 2 : 150 + 724 - 2]\n",
    "#     else:\n",
    "#         if rot_num != 0:\n",
    "#             img = np.pad(img, ((256, 256), (256, 256)), mode = 'reflect')\n",
    "#             img = rotate(img, rot_val, reshape = False)\n",
    "#             img = img[150 + 2 : 150 + 724 - 2, 150 + 2 : 150 + 724 - 2]\n",
    "            \n",
    "#     if sh_val_v == 1:\n",
    "#         img = img[8 : img.shape[0] - 8, :]\n",
    "#     if sh_val_h == 1:\n",
    "#         img = img[:, 8 : img.shape[1] - 8]\n",
    "        \n",
    "#     return img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magic(data, offset, pic, gt, img_num):\n",
    "    \n",
    "    def mms(X, a, b):\n",
    "        _min = X.min()\n",
    "        _max = X.max()\n",
    "        X = (X - _min) / (_max - _min) if _min != _max else np.zeros_like(X)\n",
    "        return X * (b - a) + a \n",
    "\n",
    "    v = gt.shape[0] // 16\n",
    "    h = gt.shape[1] // 16\n",
    "\n",
    "    B, G, R = [np.array(pic[:, :, c], float) for c in range(3)]\n",
    "    total = R + G + B\n",
    "    r = np.divide(R, total, out=np.zeros_like(total), where=total!=0)\n",
    "    g = np.divide(G, total, out=np.zeros_like(total), where=total!=0)\n",
    "    b = np.divide(B, total, out=np.zeros_like(total), where=total!=0)\n",
    "\n",
    "\n",
    "    #VI generation\n",
    "    F = {} # Imagens Filtradas\n",
    "    F[\"ExG\"] = 2 * g - r - b\n",
    "    #print(\"ExGR\")\n",
    "    F[\"ExGR\"] = F[\"ExG\"] - 1.4 * r - g\n",
    "    #print(\"CIVE\")\n",
    "    F[\"CIVE\"] = 0.441 * r - 0.881 * g + 0.385 * b + 18.78745\n",
    "    #print(\"VEG\")\n",
    "    divisor = 2 + r ** 0.667 * b ** (1 - 0.667)\n",
    "    F[\"VEG\"] = np.divide(g, divisor, out=np.zeros_like(divisor), where=divisor!=0)\n",
    "    #print(\"WI\")\n",
    "    divisor = r - g\n",
    "    F[\"WI\"] = np.divide((g - b), divisor, out=np.zeros_like(divisor), where=divisor!=0)\n",
    "    #print(\"NGRDI\")\n",
    "    divisor = G + R\n",
    "    F[\"NGRDI\"] = np.divide((G - R), divisor, out=np.zeros_like(divisor), where=divisor!=0)\n",
    "\n",
    "    N = {f : mms(F[f], 0, 8 - .001).astype(int) for f in F} # Imagens filtradas Normalizadas\n",
    "\n",
    "\n",
    "    #Haralick\n",
    "    for ix, f in enumerate(names_VI):\n",
    "        blocks = view_as_blocks(N[f], (16,16)).reshape((v * h, 16, 16))\n",
    "        for j, b in enumerate(blocks):\n",
    "            # b = np.array(mms(b, (0.5,7.5)) , dtype=\"uint8\") # normaliza apenas o bloco\n",
    "            P = greycomatrix(b, [1], (np.pi/4, 0, 3*np.pi/2, 7*np.pi/4), 8)\n",
    "    #         VI[f][offset + j, :24] = get_features(P)\n",
    "            data[offset + j, ix * 24 : (ix + 1) * 24] = get_features(P)\n",
    "\n",
    "    #\"STATS\"\n",
    "    for ix, f in enumerate(names_VI):\n",
    "        blocks = view_as_blocks(F[f], (16,16)).reshape((v * h, 16, 16))\n",
    "        for j, b in enumerate(blocks):\n",
    "    #         VI[f][offset + j, 24:] = get_stats(b)\n",
    "            data[offset + j, 144 + ix * 7 : 144 + (ix + 1) * 7] = get_stats(b)\n",
    "\n",
    "    #BIC\n",
    "    bic_pic = sum(mms(pic[:, :, c], 0, 4 - .001).astype(int) * (4**c) for c in range(3))\n",
    "    blocks = view_as_blocks(bic_pic, (16,16)).reshape((v * h, 16, 16))\n",
    "    for j, b in enumerate(blocks):\n",
    "    #     bic[offset + j, 0:64], bic[b, 64:64*2] = BIC(b, 64)\n",
    "        data[offset + j, 186 : 186 + 128] = BIC(b, 64)\n",
    "\n",
    "    #GT and extra\n",
    "    blocks = view_as_blocks(gt, (16,16)).reshape((v * h, 16, 16))\n",
    "    for j, b in enumerate(blocks):\n",
    "        \n",
    "        # data[offset + j, -7 : -1] = (b > .5).mean() > .5, img_num, noise_num, rot_num, sh_num, j\n",
    "        data[offset + j, -4 : -1] = (b > .5).mean() > .5, img_num, j\n",
    "        # -1 is used for the base number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laço de criação das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLKSPIMG = 58844 # 58844 - blocks per image\n",
    "BLKSPIMG = 32 * 32 # 58844 - blocks per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_cols = ['target', 'img_num', 'block_num', 'base_num']\n",
    "features_count = np.array([\n",
    "    6 * 24, # haralick\n",
    "    6 * 7, # stats\n",
    "    64 + 64, # bic\n",
    "    len(extra_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = []\n",
    "\n",
    "for f in names_VI:\n",
    "    for ext in extractors:\n",
    "        for ang in angles:\n",
    "            col_names.append(\"%s_%s_%s\" % (f, ext, ang))\n",
    "            \n",
    "for f in names_VI:\n",
    "    for s in statistics:\n",
    "        col_names.append(\"%s_%s\" % (f, s))\n",
    "\n",
    "for i in range(64):\n",
    "    col_names.append(\"border_%d\" % (i))\n",
    "    \n",
    "for i in range(64):\n",
    "    col_names.append(\"interior_%d\" % (i))\n",
    "    \n",
    "col_names.extend(extra_cols)\n",
    "\n",
    "len(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144 186 314 318]\n"
     ]
    }
   ],
   "source": [
    "n_features = int(features_count.sum())\n",
    "print(features_count.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60416, 318)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shape = (n_images * BLKSPIMG,  n_features)\n",
    "data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_data = Array('d', n_images * BLKSPIMG * n_features, lock=False)\n",
    "# QUESTION: always initialize with 0 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.frombuffer(shared_data).reshape(data_shape)\n",
    "data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(args):\n",
    "\n",
    "    i, img_num, path_pic, path_gt = args\n",
    "    offset = i * BLKSPIMG    \n",
    "    pic = imread(path_pic, False)[:, :, : 3]\n",
    "    gt = imread(path_gt, as_gray=True) # all valid images when read like this have a max value of 1.0\n",
    "    data = np.frombuffer(shared_data).reshape(data_shape)\n",
    "    \n",
    "    magic(data, offset, pic, gt, img_num)\n",
    "    offset += BLKSPIMG\n",
    "    \n",
    "#     for noise in noises:\n",
    "#         for rotation in rotations:\n",
    "#             for shift in shifts:\n",
    "#                 pic = transform_img(pic.copy(), noise, rotation, shift)\n",
    "#                 gt =  transform_img(gt.copy(), noise, rotation, shift)\n",
    "#                 magic(data, offset, pic, gt, img_num, noise[0], rotation[0], shift[0])\n",
    "#                 v = gt.shape[0] // 16\n",
    "#                 h = gt.shape[1] // 16\n",
    "#                 offset += v * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# i = 0\n",
    "# args = i, paths['num'].iloc[i], paths['pic'].iloc[i], paths['gt'].iloc[i]\n",
    "\n",
    "# worker(args)\n",
    "\n",
    "# print(data[BLKSPIMG :, -5].mean(), data[: BLKSPIMG, -5].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function is required to use the shared variables as global variables in the shared enviroment.\n",
    "\"\"\"\n",
    "def _init(init_args):\n",
    "#     global shared_array\n",
    "    shared_array = init_args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define pool of processes\n",
    "\"\"\"\n",
    "pool = Pool(processes=7, initializer=_init, initargs=([shared_data],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77.3 ms, sys: 42.5 ms, total: 120 ms\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Execute pool of processes\n",
    "\"\"\"\n",
    "pool.map(worker, ((\n",
    "    i,\n",
    "    paths['num'].iloc[i],\n",
    "    paths['pic'].iloc[i],\n",
    "    paths['gt'].iloc[i]\n",
    ") for i in range(min(n_images, 70))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.frombuffer(shared_data).reshape(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54296875 0.8619791666666666\n"
     ]
    }
   ],
   "source": [
    "print(data[12 * BLKSPIMG :, -4].mean(), data[: 12 * BLKSPIMG, -4].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['base_num'] = 1\n",
    "df.loc[df.img_num <= 17, 'base_num'] = 0\n",
    "df.loc[df.img_num >= 40, 'base_num'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.base_num.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 253 ms, total: 11.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv('../IC2017_DATA/blocks_simple_01.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
